# ATEC-TASK2-Rank2

队名：地平线

队员：自闭

​			呆毛辉

​			Training.L

成绩 81.7 科技新星榜 Top2 总榜 Top3

线上赛总结：

1.对赛题的理解

​		题目要求在数据保护场景下的联合计算分析，从而思考隐私保护技术的实践问题。从交易欺诈场景入手，提供关于数字货币的数据集进行联合学习。思考什么是“**联合学习**”，最简单理解一个事物就是先百度一下，进行一次了解，我了解到”**联合学习**“最早由谷歌提出，是一种分布式机器学习训练方法，最常见的形式为Server-Client 形式，由一个中央服务器，搭配分散各地来参与训练的多个节点（也就是Client）。各节点主机先从中央服务器下载模型，在本地端以自己的资料来进行训练，完成训练后，再将各自模型的权重上传至中央服务器，由中央服务器来聚合（Aggregate）这些权重。这种分布式训练方法，可套用在不同机器学习模型的训练过程。那么本题非常类似，40个图相当于四十台客户端，也就是所谓的worker.py;这些worker.py之间是不能传递数据特征的，每一个worker.py只能和server.py进行数据交互的。因此在考虑这个东西时候，问题出现了，每张图的差别很大，因此需要一个方式去优化这种差别，或者说将模型可以很好的适应这种差别的。

2.对数据的分析思路

​	2.1.节点特征包括93维交易本身的特征，以及72维与邻居节点聚合后的特征，可以明确的是加起来一共是165维的特征，并且所有的特征都是匿名的特征，因此很难去做特征工程的，没办法对于每个特征进行分析的。

​	2.2 题目要求四十个图不能进行数据交互的，可以很轻易的查看出来，每张的图的差别正负样本很大，最'好'的一张图正负样本的比例为3:1，最‘坏’的一张的图的正负样本比例为1000:1，一个图中只有10个左右的负样本的。所以对于模型来说，这张‘坏’的图对于模型来说其干扰的作用，可以采取一些比如数据加强的方式来解决的。这是第三节的内容。

​	2.3 测试数据为9张的图的数据，因此可以进行分图预测，可能效果会更好的。

​	2.4 可以考虑从**边集**数据特征入手，来增强数据特征的。

3.模型方案解析

​	3.1 baseline改进版 增加了网络层(layer)层数，改变每层的节点数。

|      模型      | 模型架构                                             | 模型结果 |
| :------------: | :--------------------------------------------------- | :------: |
|    baseline    | Linear(165, 50)<br/>Linear(50,2)                     |  76.25   |
| baseline改进版 | Linear(165, 64)<br/>Linear(64, 32)<br/>Linear(32, 2) |  77.24   |

​    3.2 GAT 图神经网络,使用节点特征和边集的特征。

| 模型 | 模型结果 |
| :--: | :------: |
| GAT  |  14.95   |

​	3.3 baseline+/传统数据采样(上采样)

| 模型      | 模型架构                                               | loss函数         | 下采样                                                       | 验证集 | 模型结果(测试集) |
| --------- | ------------------------------------------------------ | ---------------- | ------------------------------------------------------------ | ------ | ---------------- |
| baseline+ | Linear(165, 128)<br/>Linear(128, 32)<br/>Linear(32, 2) | CrossEntropyLoss | 否                                                           | 81.9   | 79.2             |
| baseline+ | Linear(165, 128)<br/>Linear(128, 32)<br/>Linear(32, 2) | CrossEntropyLoss | 进行下采样，对于<br/>少的负样本进行下采样一次<br/>两次，三次来增加数据 | 82.7   | 75.2             |
| baseline+ | Linear(165, 128)<br/>Linear(128, 32)<br/>Linear(32, 2) | CrossEntropyLoss | 进行下采样，对于<br/>一部分负样本比较少的，就是负样本与<br/>正样本差别达到10:1以上进行进行下采样一次<br/>两次，三次来增加数据 | 83.5   | 77.2             |

3.4 baseline改进版/FocalLoss优化

| 模型               | 模型架构                                                 | loss函数                                            | 模型结果 |
| ------------------ | -------------------------------------------------------- | --------------------------------------------------- | -------- |
| baseline改进版     | Linear(165, 64)<br/>Linear(64, 32)<br/>Linear(32, 2)     | CrossEntropyLoss                                    | 77.24    |
| baseline+          | Linear(165, 128)  <br/>Linear(128, 32)<br/>Linear(32, 2) | CrossEntropyLoss                                    | 79.2     |
| baseline+FocalLoss | Linear(165, 128)<br/>Linear(128, 32)<br/>Linear(32, 2)   | FocalLoss(class_num=2, alpha=[0.75, 0.25], gamma=2) | 80       |
| baseline+FocalLoss | Linear(165, 128)<br/>Linear(128, 32)<br/>Linear(32, 2)   | FocalLoss(class_num=2, alpha=[0.8, 0.2], gamma=2)   | 80.33    |

*对于Focalloss来说，论文原文中是alpha=[0.75,0.25],gamma=2的效果最好，但是经过试验证明在这个数据集上面alpha=[0.8,0.2],gamma=2效果最好

*由于使用了Focalloss可以有效的减少正负样本数量差别导致的模型预测误差，因此没有做Focalloss的对比试验

​	3.5 融合边集特征

​				算法思想：经过前面的实验可以得出使用baseline+Focalloss已经达到了0.8的准确率，那么可以得出对于任何节点值使用节点的特征，模型预测出来节点的类型可以的达到0.8以上。前文中所有的train过程只使用了知道**标签**的数据，不知道标签的数据还未使用，并且，边集特征还未使用。

​				算法步骤：

​						Step1：使用0.8准确度的baseline+Focalloss将整张图预测出来，因此可以得出所有节点的标签（整体的准确度为0.8，是可信的)。![image-20211108192445645](C:\Users\daimaohui\AppData\Roaming\Typora\typora-user-images\image-20211108192445645.png)

 * 左边图中节点为标签为2是没有标签，从左边到右边就是一张图进行预测的过程，但是存在节点被误判的情况。

   ​		Step2:对任意的一个节点进行加权，比如说一个节点A，与它连接的有四个节点B,C,D,E 进行step1的判断，可以得出B,C,D,E的节点类型为0,1,1,1，那么节点A受到周围节点的影响的权重为(x+y+y+y)/4,其中x为0对应的权重，y为1对应的权重。

   ​		Step3:将Step2得到的权重带入到165维特征中，作为第165维特征，重新构建网络，进行训练。

   

   | 模型               | 模型架构                                               | loss函数                                          | 边的权重    | 模型结果 |
   | ------------------ | ------------------------------------------------------ | ------------------------------------------------- | ----------- | -------- |
   | baseline+FocalLoss | Linear(165, 128)<br/>Linear(128, 32)<br/>Linear(32, 2) | FocalLoss(class_num=2, alpha=[0.8, 0.2], gamma=2) |             | 80.33    |
   | 二次建模           | Linear(166, 128)<br/>Linear(128, 40)<br/>Linear(40, 2) | FocalLoss(class_num=2, alpha=[0.8, 0.2], gamma=2) | x=2<br/>y=1 | 81.16    |

   3.6 训练到收敛

   ​	经过3.5之后，可以得出经过二次建模，模型效果得到提升，但是由于我们使用预测数据去预测数据（不可靠的），因此需要进行多次训练使得结果收敛，所谓收敛就是，使用二次建模的模型来预测测试集的所有节点分类，然后将节点分类带入到二次建模的模型中，重新进行预测。

   

   ​	

   | 模型               | 模型架构                                               | loss函数                                          | 边的权重    | 模型结果 |
   | ------------------ | ------------------------------------------------------ | ------------------------------------------------- | ----------- | -------- |
   | baseline+FocalLoss | Linear(165, 128)<br/>Linear(128, 32)<br/>Linear(32, 2) | FocalLoss(class_num=2, alpha=[0.8, 0.2], gamma=2) |             | 80.33    |
   | 二次建模           | Linear(166, 128)<br/>Linear(128, 40)<br/>Linear(40, 2) | FocalLoss(class_num=2, alpha=[0.8, 0.2], gamma=2) | x=2<br/>y=1 | 81.16    |
   | 训练收敛           |                                                        |                                                   |             | 81.7     |

改进方式：

​	1.由于本文中方法只提取新特征只有一维，因此对于神经网络来说，这一维的特征的效果可能不是很显著，应该可以提取多维的特征来进行模型的加强。这里有一个方式就是将邻居节点的所有特征与本节点的特征进行融合得到330维的特征。

​	2.对于图神经网络来说，已经知道图神经网络为什么在本数据集的劣势，由于每张图的数据太悬殊，差别太大了。但是最近几年已经有很多论文提出相应的解决方式，由于比赛时间的原因，我没有去测试这些方式的可行性。可以后续去尝试。可以尝试以下论文

论文链接：https://arxiv.org/pdf/2103.08826.pdf

[1] P. Velickovic, G. Cucurull, A. Casanova, A. Romero, P. Lio, Y. Bengio. Graph Attention Networks. NeuraIPS 2018.

[2] Tsung-Yi Lin, Priya Goyal,Ross B. Girshick, Kaiming He, Published 2017,Computer Science,2017 IEEE International Conference on Computer Vision (ICCV).

